{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edit based distance to canonical uniprot sequences\n",
    "### Hamming + normalized col\n",
    "### Levenshtein + normalized col \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairwise sequence alignment is the process of comparing only two strings\n",
    "* edit distance hard to compute for longer strings\n",
    "* hamming needs same length, but i like that it looks at positions, since one insertions is one change but that could through off positions by alot\n",
    "\n",
    "* hamming and levenshtein are both edit based, but hamming penalizes on positional differences whereas levenshtein does not\n",
    "\n",
    "### Levenshtein distance = \n",
    "- In information theory, linguistics and computer science, the Levenshtein distance is a string metric for measuring the difference between two sequences. Informally, the Levenshtein distance between two words is the minimum number of single-character edits (insertions, deletions or substitutions) required to change one word into the other. It is named after the Soviet mathematician Vladimir Levenshtein, who considered this distance in 1965.[1]\n",
    "\n",
    "\n",
    "### Damerau–Levenshtein distance = \n",
    "- differs from the classical Levenshtein distance by including transpositions among its allowable operations in addition to the three classical single-character edit operations (insertions, deletions and substitutions).[4][2]\n",
    "\n",
    "##### From the elementary costs, we set\n",
    "> δE = min{cost of σ : σ ∈ Sx,y}\n",
    "    \n",
    "    where Sx,y is the set of sequences of elementary edit operationsthat transform x into y, and the cost of an element σ ∈ Sx,y is the sum of the costs of the edit operations of the sequence σ. The function δE is then a distance on Σ ∗, and it is called the edit distance (Damerau-Levenshtein distance).\n",
    "\n",
    "---\n",
    "\n",
    "### Relationship with other edit distance metrics\n",
    "There are other popular measures of edit distance, which are calculated using a different set of allowable edit operations. For instance,\n",
    "1. the Levenshtein distance allows deletion, insertion and substitution;\n",
    "2. the Damerau–Levenshtein distance allows insertion, deletion, substitution, and the transposition of two adjacent characters;\n",
    "3. the longest common subsequence (LCS) distance allows only insertion and deletion, not substitution;\n",
    "4. the Hamming distance allows only substitution, hence, it only applies to strings of the same length.\n",
    "> Edit distance is usually defined as a parameterizable metric calculated with a specific set of allowed edit operations, and each operation is assigned a cost (possibly infinite). This is further generalized by DNA sequence alignment algorithms such as the Smith–Waterman algorithm, which make an operation's cost depend on where it is applied.\n",
    "\n",
    "**Levenshtein counts the number of edits (insertions, deletions, or substitutions) needed to convert one string to the other. Damerau-Levenshtein is a modified version that also considers transpositions as single edits. Although the output is the integer number of edits, this can be normalized to give a similarity value by the formula**\n",
    "\n",
    "> 1 - (edit distance / length of the larger of the two strings)\n",
    "\n",
    "    The Jaro algorithm is a measure of characters in common, being no more than half the length of the longer string in distance, with consideration for transpositions. Winkler modified this algorithm to support the idea that differences near the start of the string are more significant than differences near the end of the string. Jaro and Jaro-Winkler are suited for comparing smaller strings like words and names.\n",
    "\n",
    "Deciding which to use is not just a matter of performance. It's important to pick a method that is suited to the nature of the strings you are comparing. In general though, both of the algorithms you mentioned can be expensive, because each string must be compared to every other string, and with millions of strings in your data set, that is a tremendous number of comparisons. That is much more expensive than something like computing a phonetic encoding for each string, and then simply grouping strings sharing identical encodings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i want to use both the hamming distance and the levenshtein distance\n",
    "- both edit distance algorithms, hamming considers positional difference, therefore only allows substitutions\n",
    "- levenshtein allows substitutions, deletion, and insertion of 1 AA\n",
    "- if insertion is at last position in string\n",
    "    > example MARIA + P, then both are 1\n",
    "    \n",
    "- if insertion is at first position in string\n",
    "    > example M + MARIA then leven is 1 still but hamming is 5, normalized hamming is 5/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval # for mismap_score func\n",
    "import difflib\n",
    "import jellyfish\n",
    "import textdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/Users/mariapalafox/Desktop/Toolbox/\")\n",
    "from all_funx import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.display.max_seq_items = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = \"MARIA\"\n",
    "m2 = \"AAR\"\n",
    "m3 = \"MARIAA\"\n",
    "m4 = \"MMARIA\"\n",
    "print(jellyfish.hamming_distance(m, m4))\n",
    "print(textdistance.hamming.normalized_distance(m, m4))\n",
    "print(textdistance.hamming.normalized_distance(m4, m))\n",
    "# 5/6 = 0.8333333333333334 so hamming normalized takes the longest len as denom and num is # mismatched positions\n",
    "print(textdistance.levenshtein(m4, m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identicalSequences(dfEnsp, ref_dic, newcolresult, hamming, hammingNorm, levenshtein, levenshteinNorm):\n",
    "    res = []\n",
    "    ham = []\n",
    "    hamnorm = []\n",
    "    lev = []\n",
    "    levnorm = []\n",
    "    serSeq = dfEnsp['proSequence'].copy()\n",
    "    serID = dfEnsp['UniProtSP_xref'].copy()\n",
    "    for inx, val in serSeq.items():\n",
    "        pep = str(val)\n",
    "        p = pep.strip()\n",
    "        idd = str(serID[inx])\n",
    "        # check pep to dict pep sequence\n",
    "        mypep = ref_dic[idd]\n",
    "        str(mypep)\n",
    "        # identical\n",
    "        if mypep == p:\n",
    "            res.append('True')\n",
    "#             ham.append('identical')\n",
    "#             hamnorm.append('identical')\n",
    "#             lev.append('identical')\n",
    "            ham.append(textdistance.hamming(mypep, p))\n",
    "            # normalized hamming = # mismatched positions/ len of longer sequence\n",
    "            hamnorm.append(textdistance.hamming.normalized_distance(mypep, p))\n",
    "            # levenshtein score is edit based but not not penalized position, insertion at pos 1 is jsut 1 diff\n",
    "            lev.append(textdistance.levenshtein(mypep,p))\n",
    "            levnorm.append(textdistance.levenshtein.normalized_distance(mypep, p))\n",
    "        \n",
    "        # not identical to canonical\n",
    "        if mypep != p: \n",
    "            res.append('False')\n",
    "            # calculates hamming distance, penalizes positional differences, edit based distance\n",
    "            ham.append(textdistance.hamming(mypep, p))\n",
    "            # normalized hamming = # mismatched positions/ len of longer sequence\n",
    "            hamnorm.append(textdistance.hamming.normalized_distance(mypep, p))\n",
    "            # levenshtein score is edit based but not not penalized position, insertion at pos 1 is jsut 1 diff\n",
    "            lev.append(textdistance.levenshtein(mypep,p))\n",
    "            levnorm.append(textdistance.levenshtein.normalized_distance(mypep, p))\n",
    "            \n",
    "    # add new column\n",
    "    dfEnsp.loc[:,newcolresult] = res\n",
    "    dfEnsp.loc[:,hamming] = ham\n",
    "    dfEnsp.loc[:,hammingNorm] = hamnorm\n",
    "    dfEnsp.loc[:,levenshtein] = lev\n",
    "    dfEnsp.loc[:,levenshteinNorm] = levnorm\n",
    "    return dfEnsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['v96Homo_sapiens.GRCh38.pep.all.fa', 'v97Homo_sapiens.GRCh37.pep.all.fa', 'sharedv85_10272_uniqueENSP.csv', 'MISMAP_SCORED_differentNumUKBID_2124_v96_notTrue4myIdentityScore_4623.csv', 'Homo_sapiens.GRCh38.97.uniprot.tsv', 'MISMAP_SCORED_differentNumUKBID_3885_v97_True4myIdentityScore_6052.csv', 'uniprotIDs3979.csv', 'groupedMISMAP_score_85_FALSEidentity_1805.csv', 'v85_labeledEverUKBID_xref100_sourceref100_15.csv', 'MISMAP_SCORE_xref_SharedID_allReleases_3979_UKBkey.csv', '.DS_Store', 'MISMAP_SCORED_differentNumUKBID_3878_v92_True4myIdentityScore_5957.csv', 'MISMAP_SCORED_v94_ENSP_posDict_checked_10699.csv', 'v94_labeledEverUKBID_xref100_sourceref100_6097.csv', 'MISMAP_SCORED_v97_ENSP_posDict_checked_10650.csv', 'v85_labeledEverUKBID_xref100_sourceref100_14.csv', 'MISMAP_SCORED_described_10750.csv', 'MISMAP_SCORED_v96_ENSP_posDict_checked_10750.csv', 'Homo_sapiens.GRCh38.92.uniprot.tsv', 'v96_labeledEverUKBID_xref100_sourceref100_6152.csv', 'uniprotIDs_3979.csv', 'MISMAP_SCORED_sameNumUKBID_1805_v85_notTrue4myIdentityScore_4212.csv', 'all3991_everLabeled_entries_simple.csv', 'CYSLYS_failure2map', 'MISMAP_SCORED_sameNumUKBID_1805_v92_notTrue4myIdentityScore_4098.csv', 'key85_10272.csv', 'MISMAP_SCORED_differentNumUKBID_2123_v97_notTrue4myIdentityScore_4598.csv', 'v97_labeledEverUKBID_xref100_sourceref100_6064.csv', 'MISMAP_SCORED_sameNumUKBID_1805_v97_notTrue4myIdentityScore_4169.csv', 'v96_labeledEverUKBID_xref100_sourceref100_6136.csv', 'groupedMISMAP_score_97_3979.csv', 'groupedMISMAP_score_96_3979.csv', 'MISMAP_SCORE_UniprotFastaCKabund_w_UniprotCYSLYSpositionsLabeled_49.csv', 'MISMAP_SCORE_uniprot_TrueTargets_CYS_LYS_positions_3979.csv', 'MISMAP_SCORE_CYS_LYS_15447pos_3979entries.csv', 'v97Homo_sapiens.GRCh38.pep.all.fa', 'uniprot3979_IDs.csv', 'dynamic3_summaryMULTIMAPPING_ENSPid_3979.csv', 'MISMAP_SCORED_described_10479.csv', 'Homo_sapiens.GRCh38.94.uniprot.tsv', 'key92_10479.csv', 'MISMAP_SCORED_described_10650.csv', 'key97_10650.csv', 'MISMAP_SCORED_v85_ENSP_posDict_checked_10272.csv', 'groupedMISMAP_score_92_3979.csv', 'MISMAP_SCORED_differentNumUKBID_3890_v96_True4myIdentityScore_6127.csv', 'v92_labeledEverUKBID_xref100_sourceref100_5951.csv', 'dynamic_MULTIMAPPING_described_eachRelease_comparison_3979UKBIDs.csv', 'MISMAP_SCORED_described_10272.csv', 'key96_10750.csv', 'MISMAP_SCORED_differentNumUKBID_3895_v94_True4myIdentityScore_6097.csv', 'UNIPROT_GENENAME_CCDS_KEY.csv', 'key94_10699.csv', 'AllENSPcommon8939_proSequence_differences', 'groupedMISMAP_score_96_FALSEidentity_1805.csv', 'sharedv96_10750_uniqueENSP.csv', 'MISMAP_SCORE_UniprotCanonical_3979entries_valueCounts_fromDict.csv', 'MISMAP_SCORED_described_10699.csv', 'v92_labeledEverUKBID_xref100_sourceref100_5943.csv', 'dynamic4_summaryMULTIMAPPING_ENSPid_3979.csv', 'groupedMISMAP_score_85_3979.csv', 'Homo_sapiens.GRCh38.96.uniprot.tsv', 'v97_labeledEverUKBID_xref100_sourceref100_6080.csv', 'sharedv97_10650_uniqueENSP.csv', 'groupedMISMAP_score_92_FALSEidentity_1805.csv', 'v94Homo_sapiens.GRCh38.pep.all.fa', 'MISMAP_SCORED_differentNumUKBID_2116_v92_notTrue4myIdentityScore_4522.csv', 'MISMAP_SCORED_differentNumUKBID_1909_v85_notTrue4myIdentityScore_4347.csv', 'v92Homo_sapiens.GRCh38.pep.all.fa', 'v94_labeledEverUKBID_xref100_sourceref100_6112.csv', 'sharedv94_10699_uniqueENSP.csv', 'dynamic1_summaryMULTIMAPPING_ENSPid_3979.csv', 'sharedv92_10479_uniqueENSP.csv', 'groupedMISMAP_score_94_FALSEidentity_1805.csv', 'MISMAP_SCORED_differentNumUKBID_3884_v85_True4myIdentityScore_5925.csv', 'MISMAP_SCORED_sameNumUKBID_1805_v96_notTrue4myIdentityScore_4192.csv', 'MISMAP_SCORED_sameNumUKBID_1805_v94_notTrue4myIdentityScore_4173.csv', 'MISMAP_SCORE_UniprotFastaCKabund_w_UniprotCYSLYSpositionsLabeled_3979.csv', 'groupedMISMAP_score_97_FALSEidentity_1805.csv', 'dynamic_MULTIMAPPING_ENSPids_groupedby_3979ukbids.csv', 'MISMAP_ENSPseq_myIdentity_2canonUKBseq', 'dynamic2_summaryMULTIMAPPING_ENSPid_3979.csv', 'groupedMISMAP_score_94_3979.csv', 'MISMAP_SCORED_v92_ENSP_posDict_checked_10479.csv', 'dynamicALL_summaryMULTIMAPPING_ENSPid_counts_stableEntry_3979.csv', 'v85Homo_sapiens.GRCh37.pep.all.fa', 'MISMAP_SCORED_differentNumUKBID_2116_v94_notTrue4myIdentityScore_4602.csv', 'Homo_sapiens.GRCh37.85.uniprot.tsv']\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/Users/mariapalafox/Box Sync/CODE_DATA/dir_MAPpaper/TSV_UNIPROT_xref\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dictionary of canonical uniprot sequences\n",
    "refuniprot = pd.read_csv(\"MISMAP_SCORE_UniprotFastaCKabund_w_UniprotCYSLYSpositionsLabeled_3979.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniProtSP_xref</th>\n",
       "      <th>UniProt_length</th>\n",
       "      <th>proSequence</th>\n",
       "      <th>C_abundance</th>\n",
       "      <th>K_abundance</th>\n",
       "      <th>in3979xref</th>\n",
       "      <th>total_targets</th>\n",
       "      <th>pos_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q9HAS0</td>\n",
       "      <td>396</td>\n",
       "      <td>MLPSLQESMDGDEKELESSEEGGSAEERRLEPPSSSHYCLYSYRGS...</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0581</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>{182: 'C'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q86X76</td>\n",
       "      <td>327</td>\n",
       "      <td>MLGFITRPPHRFLSLLCPGLRIPQLSVLCAQPRPRAMAISSSSCEL...</td>\n",
       "      <td>0.0459</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>{161: 'K', 165: 'C', 203: 'C'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q9NQR4</td>\n",
       "      <td>276</td>\n",
       "      <td>MTSFRLALIQLQISSIKSDNVTRACSFIREAATQGAKIVSLPECFN...</td>\n",
       "      <td>0.0254</td>\n",
       "      <td>0.0652</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>{44: 'C', 52: 'K', 123: 'K', 130: 'K', 146: 'C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  UniProtSP_xref  UniProt_length  \\\n",
       "0         Q9HAS0             396   \n",
       "1         Q86X76             327   \n",
       "2         Q9NQR4             276   \n",
       "\n",
       "                                         proSequence  C_abundance  \\\n",
       "0  MLPSLQESMDGDEKELESSEEGGSAEERRLEPPSSSHYCLYSYRGS...       0.0303   \n",
       "1  MLGFITRPPHRFLSLLCPGLRIPQLSVLCAQPRPRAMAISSSSCEL...       0.0459   \n",
       "2  MTSFRLALIQLQISSIKSDNVTRACSFIREAATQGAKIVSLPECFN...       0.0254   \n",
       "\n",
       "   K_abundance  in3979xref  total_targets  \\\n",
       "0       0.0581        True              1   \n",
       "1       0.0245        True              3   \n",
       "2       0.0652        True              7   \n",
       "\n",
       "                                            pos_dict  \n",
       "0                                         {182: 'C'}  \n",
       "1                     {161: 'K', 165: 'C', 203: 'C'}  \n",
       "2  {44: 'C', 52: 'K', 123: 'K', 130: 'K', 146: 'C...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refuniprot.drop(['Unnamed: 0'],inplace=True,axis=1)\n",
    "refuniprot.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stripped the white spaces from uniprot seq col\n",
    "ukb = refuniprot['proSequence'].apply(lambda x: x.strip())\n",
    "ukb.head(3)\n",
    "refuniprot.proSequence = ukb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        396\n",
       "1        327\n",
       "2        276\n",
       "3        301\n",
       "4       2471\n",
       "5        535\n",
       "6        596\n",
       "7        503\n",
       "8        281\n",
       "9        548\n",
       "10       127\n",
       "11       767\n",
       "12      1436\n",
       "13      2090\n",
       "14       331\n",
       "15       400\n",
       "16       172\n",
       "17      1960\n",
       "18      2157\n",
       "19       587\n",
       "20       706\n",
       "21       456\n",
       "22      1025\n",
       "23       205\n",
       "24       390\n",
       "25       377\n",
       "26       436\n",
       "27       887\n",
       "28       271\n",
       "29      1249\n",
       "        ... \n",
       "3949     311\n",
       "3950     391\n",
       "3951     289\n",
       "3952     633\n",
       "3953    3433\n",
       "3954     119\n",
       "3955     213\n",
       "3956     466\n",
       "3957    3174\n",
       "3958     699\n",
       "3959     313\n",
       "3960     601\n",
       "3961     508\n",
       "3962    5183\n",
       "3963     425\n",
       "3964    1555\n",
       "3965    1090\n",
       "3966    3258\n",
       "3967     310\n",
       "3968     123\n",
       "3969     475\n",
       "3970     153\n",
       "3971    2620\n",
       "3972     649\n",
       "3973     489\n",
       "3974    1375\n",
       "3975    1888\n",
       "3976    1464\n",
       "3977     944\n",
       "3978     313\n",
       "Name: proSequence, Length: 3979, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refuniprot['proSequence'].apply(lambda x: len(x))\n",
    "# lenght matches df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3979\n",
      "3978\n"
     ]
    }
   ],
   "source": [
    "# are all uniprot seq unique?\n",
    "seq = refuniprot.proSequence.tolist()\n",
    "print(len(seq))\n",
    "print(len(set(seq)))\n",
    "# cant use sequence as key since there is one duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniProtSP_xref</th>\n",
       "      <th>UniProt_length</th>\n",
       "      <th>proSequence</th>\n",
       "      <th>C_abundance</th>\n",
       "      <th>K_abundance</th>\n",
       "      <th>in3979xref</th>\n",
       "      <th>total_targets</th>\n",
       "      <th>pos_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>P86791</td>\n",
       "      <td>482</td>\n",
       "      <td>MAAAAAGAGSGPWAAQEKQFPPALLSFFIYNPRFGPREGQEENKIL...</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>{358: 'C'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>P86790</td>\n",
       "      <td>482</td>\n",
       "      <td>MAAAAAGAGSGPWAAQEKQFPPALLSFFIYNPRFGPREGQEENKIL...</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>{358: 'C'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     UniProtSP_xref  UniProt_length  \\\n",
       "176          P86791             482   \n",
       "2704         P86790             482   \n",
       "\n",
       "                                            proSequence  C_abundance  \\\n",
       "176   MAAAAAGAGSGPWAAQEKQFPPALLSFFIYNPRFGPREGQEENKIL...       0.0166   \n",
       "2704  MAAAAAGAGSGPWAAQEKQFPPALLSFFIYNPRFGPREGQEENKIL...       0.0166   \n",
       "\n",
       "      K_abundance  in3979xref  total_targets    pos_dict  \n",
       "176        0.0726        True              1  {358: 'C'}  \n",
       "2704       0.0726        True              1  {358: 'C'}  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DUP = refuniprot[refuniprot.duplicated(['proSequence'], keep=False)]\n",
    "DUP\n",
    "# CCZ1 Gene(Protein Coding) \n",
    "# CCZ1 Homolog, Vacuolar Protein Trafficking And Biogenesis Associated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dictionary from ID and Sequence columns\n",
    "ref_dic = dict(zip(refuniprot.UniProtSP_xref, refuniprot.proSequence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adding distance values to csv of each release including TRUE / FALSE identity scores \n",
    "- all distance scores in relationship to canonical ukb sequence in which the ENSP ID is linked to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/mariapalafox/Box Sync/CODE_DATA/dir_MAPpaper/TSV_UNIPROT_xref/MISMAP_ENSPseq_myIdentity_2canonUKBseq/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensembl TRUE AND FALSE all rows\n",
    "v85= pd.read_csv(\"MISMAP_SCORE_fasta85_CanonicalUKB_identitycol_distanceScores_10272.csv\")  \n",
    "v92= pd.read_csv(\"MISMAP_SCORE_fasta92_CanonicalUKB_identitycol_distanceScores_10479.csv\")  \n",
    "v94= pd.read_csv(\"MISMAP_SCORE_fasta94_CanonicalUKB_identitycol_distanceScores_10699.csv\")  \n",
    "v96= pd.read_csv(\"MISMAP_SCORE_fasta96_CanonicalUKB_identitycol_distanceScores_10750.csv\")  \n",
    "v97= pd.read_csv(\"MISMAP_SCORE_fasta97_CanonicalUKB_identitycol_distanceScores_10650.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  matchedUKBcanonical  Count\n",
      "0                True   5925\n",
      "1               False   4347\n"
     ]
    }
   ],
   "source": [
    "v85 = identicalSequences(v85, ref_dic, \"matchedUKBcanonical\", \"hamming_distance\", \"hamming_normalized_dist\", \"levenshtein_distance\", \"levenshtein_normalized_dist\")\n",
    "checkColumnValues(v85,'matchedUKBcanonical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  matchedUKBcanonical  Count\n",
      "0                True   5957\n",
      "1               False   4522\n"
     ]
    }
   ],
   "source": [
    "v92 = identicalSequences(v92, ref_dic, \"matchedUKBcanonical\", \"hamming_distance\", \"hamming_normalized_dist\", \"levenshtein_distance\", \"levenshtein_normalized_dist\")\n",
    "checkColumnValues(v92, 'matchedUKBcanonical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  matchedUKBcanonical  Count\n",
      "0                True   6097\n",
      "1               False   4602\n"
     ]
    }
   ],
   "source": [
    "v94 = identicalSequences(v94, ref_dic, \"matchedUKBcanonical\", \"hamming_distance\", \"hamming_normalized_dist\", \"levenshtein_distance\", \"levenshtein_normalized_dist\")\n",
    "checkColumnValues(v94, 'matchedUKBcanonical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  matchedUKBcanonical  Count\n",
      "0                True   6127\n",
      "1               False   4623\n"
     ]
    }
   ],
   "source": [
    "v96 = identicalSequences(v96, ref_dic, \"matchedUKBcanonical\", \"hamming_distance\", \"hamming_normalized_dist\", \"levenshtein_distance\", \"levenshtein_normalized_dist\")\n",
    "checkColumnValues(v96, 'matchedUKBcanonical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  matchedUKBcanonical  Count\n",
      "0                True   6052\n",
      "1               False   4598\n"
     ]
    }
   ],
   "source": [
    "v97 = identicalSequences(v97, ref_dic, \"matchedUKBcanonical\", \"hamming_distance\", \"hamming_normalized_dist\", \"levenshtein_distance\", \"levenshtein_normalized_dist\")\n",
    "checkColumnValues(v97, 'matchedUKBcanonical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping 1 version of score columns\n",
    "v85.drop(['Unnamed: 0','hammingScore', 'hamNormalizedScore','levenshteinScore'],inplace=True,axis=1)\n",
    "v92.drop(['Unnamed: 0','hammingScore', 'hamNormalizedScore','levenshteinScore'],inplace=True,axis=1)\n",
    "v94.drop(['Unnamed: 0','hammingScore', 'hamNormalizedScore','levenshteinScore'],inplace=True,axis=1)\n",
    "v96.drop(['Unnamed: 0','hammingScore', 'hamNormalizedScore','levenshteinScore'],inplace=True,axis=1)\n",
    "v97.drop(['Unnamed: 0','hammingScore', 'hamNormalizedScore','levenshteinScore'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENSPv</th>\n",
       "      <th>ENSP</th>\n",
       "      <th>Length</th>\n",
       "      <th>proSequence</th>\n",
       "      <th>MISMAP_SCORE_ENSP</th>\n",
       "      <th>UniProtSP_xref</th>\n",
       "      <th>Identical_UKB_seq</th>\n",
       "      <th>matchedUKBcanonical</th>\n",
       "      <th>hamming_distance</th>\n",
       "      <th>hamming_normalized_dist</th>\n",
       "      <th>levenshtein_distance</th>\n",
       "      <th>levenshtein_normalized_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSP00000313454.4</td>\n",
       "      <td>ENSP00000313454</td>\n",
       "      <td>1052</td>\n",
       "      <td>MEGSEPVAAHQGEEASCSSWGTGSTNKNLPIMSTASVEIDDALYSR...</td>\n",
       "      <td>True</td>\n",
       "      <td>A0AVT1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSP00000399234.2</td>\n",
       "      <td>ENSP00000399234</td>\n",
       "      <td>389</td>\n",
       "      <td>MEGSEPVAAHQGEEASCSSWGTGSTNKNLPIMSTASVEIDDALYSR...</td>\n",
       "      <td>True</td>\n",
       "      <td>A0AVT1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>684</td>\n",
       "      <td>0.650190</td>\n",
       "      <td>663</td>\n",
       "      <td>0.630228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSP00000251527.5</td>\n",
       "      <td>ENSP00000251527</td>\n",
       "      <td>893</td>\n",
       "      <td>MTPPSRAEAGVRRSRVPSEGRWRGAEPPGISASTQPASAGRAARHC...</td>\n",
       "      <td>True</td>\n",
       "      <td>A0FGR8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>859</td>\n",
       "      <td>0.932682</td>\n",
       "      <td>70</td>\n",
       "      <td>0.076004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENSP00000279907.7</td>\n",
       "      <td>ENSP00000279907</td>\n",
       "      <td>1464</td>\n",
       "      <td>MAGIIKKQILKHLSRFTKNLSPDKINLSTLKGEGELKNLELDEEVL...</td>\n",
       "      <td>True</td>\n",
       "      <td>A0JNW5</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ENSPv             ENSP  Length  \\\n",
       "0  ENSP00000313454.4  ENSP00000313454    1052   \n",
       "1  ENSP00000399234.2  ENSP00000399234     389   \n",
       "2  ENSP00000251527.5  ENSP00000251527     893   \n",
       "3  ENSP00000279907.7  ENSP00000279907    1464   \n",
       "\n",
       "                                         proSequence  MISMAP_SCORE_ENSP  \\\n",
       "0  MEGSEPVAAHQGEEASCSSWGTGSTNKNLPIMSTASVEIDDALYSR...               True   \n",
       "1  MEGSEPVAAHQGEEASCSSWGTGSTNKNLPIMSTASVEIDDALYSR...               True   \n",
       "2  MTPPSRAEAGVRRSRVPSEGRWRGAEPPGISASTQPASAGRAARHC...               True   \n",
       "3  MAGIIKKQILKHLSRFTKNLSPDKINLSTLKGEGELKNLELDEEVL...               True   \n",
       "\n",
       "  UniProtSP_xref  Identical_UKB_seq matchedUKBcanonical  hamming_distance  \\\n",
       "0         A0AVT1               True                True                 0   \n",
       "1         A0AVT1              False               False               684   \n",
       "2         A0FGR8              False               False               859   \n",
       "3         A0JNW5               True                True                 0   \n",
       "\n",
       "   hamming_normalized_dist  levenshtein_distance  levenshtein_normalized_dist  \n",
       "0                 0.000000                     0                     0.000000  \n",
       "1                 0.650190                   663                     0.630228  \n",
       "2                 0.932682                    70                     0.076004  \n",
       "3                 0.000000                     0                     0.000000  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v85.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENSPv</th>\n",
       "      <th>ENSP</th>\n",
       "      <th>Length</th>\n",
       "      <th>proSequence</th>\n",
       "      <th>MISMAP_SCORE_ENSP</th>\n",
       "      <th>UniProtSP_xref</th>\n",
       "      <th>Identical_UKB_seq</th>\n",
       "      <th>matchedUKBcanonical</th>\n",
       "      <th>hamming_distance</th>\n",
       "      <th>hamming_normalized_dist</th>\n",
       "      <th>levenshtein_distance</th>\n",
       "      <th>levenshtein_normalized_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSP00000313454.4</td>\n",
       "      <td>ENSP00000313454</td>\n",
       "      <td>1052</td>\n",
       "      <td>MEGSEPVAAHQGEEASCSSWGTGSTNKNLPIMSTASVEIDDALYSR...</td>\n",
       "      <td>True</td>\n",
       "      <td>A0AVT1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSP00000399234.2</td>\n",
       "      <td>ENSP00000399234</td>\n",
       "      <td>389</td>\n",
       "      <td>MEGSEPVAAHQGEEASCSSWGTGSTNKNLPIMSTASVEIDDALYSR...</td>\n",
       "      <td>True</td>\n",
       "      <td>A0AVT1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>684</td>\n",
       "      <td>0.650190</td>\n",
       "      <td>663</td>\n",
       "      <td>0.630228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSP00000251527.6</td>\n",
       "      <td>ENSP00000251527</td>\n",
       "      <td>845</td>\n",
       "      <td>MSGARGEGPEAGAGGAGGRAAPENPGGVLSVELPGLLAQLARSFAL...</td>\n",
       "      <td>True</td>\n",
       "      <td>A0FGR8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>859</td>\n",
       "      <td>0.932682</td>\n",
       "      <td>77</td>\n",
       "      <td>0.083605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENSP00000279907.7</td>\n",
       "      <td>ENSP00000279907</td>\n",
       "      <td>1464</td>\n",
       "      <td>MAGIIKKQILKHLSRFTKNLSPDKINLSTLKGEGELKNLELDEEVL...</td>\n",
       "      <td>True</td>\n",
       "      <td>A0JNW5</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENSP00000349285.3</td>\n",
       "      <td>ENSP00000349285</td>\n",
       "      <td>522</td>\n",
       "      <td>MAGIIKKQILKHLSRFTKNLSPDKINLSTLKGEGELKNLELDEEVL...</td>\n",
       "      <td>True</td>\n",
       "      <td>A0JNW5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>948</td>\n",
       "      <td>0.647541</td>\n",
       "      <td>942</td>\n",
       "      <td>0.643443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ENSP00000260777.11</td>\n",
       "      <td>ENSP00000260777</td>\n",
       "      <td>571</td>\n",
       "      <td>MVIEEVNFMQNHLEIEKTCRESAEALATKLNKENKTLKRISMLYMA...</td>\n",
       "      <td>True</td>\n",
       "      <td>A0MZ66</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>583</td>\n",
       "      <td>0.923930</td>\n",
       "      <td>60</td>\n",
       "      <td>0.095087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ENSP00000347532.4</td>\n",
       "      <td>ENSP00000347532</td>\n",
       "      <td>631</td>\n",
       "      <td>MNSSDEEKQLQLITSLKEQAIGEYEDLRAENQKTKEKCDKIRQERD...</td>\n",
       "      <td>True</td>\n",
       "      <td>A0MZ66</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ENSP00000376635.4</td>\n",
       "      <td>ENSP00000376635</td>\n",
       "      <td>498</td>\n",
       "      <td>MVIEEVNFMQNHLEIEKTCRESAEALATKLNKENKTLKRISMLYMA...</td>\n",
       "      <td>True</td>\n",
       "      <td>A0MZ66</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>587</td>\n",
       "      <td>0.930269</td>\n",
       "      <td>133</td>\n",
       "      <td>0.210777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ENSP00000376636.3</td>\n",
       "      <td>ENSP00000376636</td>\n",
       "      <td>558</td>\n",
       "      <td>MNSSDEEKQLQLITSLKEQAIGEYEDLRAENQKTKEKCDKIRQERD...</td>\n",
       "      <td>True</td>\n",
       "      <td>A0MZ66</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>73</td>\n",
       "      <td>0.115689</td>\n",
       "      <td>73</td>\n",
       "      <td>0.115689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ENSP00000480109.1</td>\n",
       "      <td>ENSP00000480109</td>\n",
       "      <td>456</td>\n",
       "      <td>MNSSDEEKQLQLITSLKEQAIGEYEDLRAENQKTKEKCDKIRQERD...</td>\n",
       "      <td>True</td>\n",
       "      <td>A0MZ66</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>178</td>\n",
       "      <td>0.282092</td>\n",
       "      <td>175</td>\n",
       "      <td>0.277338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ENSPv             ENSP  Length  \\\n",
       "0   ENSP00000313454.4  ENSP00000313454    1052   \n",
       "1   ENSP00000399234.2  ENSP00000399234     389   \n",
       "2   ENSP00000251527.6  ENSP00000251527     845   \n",
       "3   ENSP00000279907.7  ENSP00000279907    1464   \n",
       "4   ENSP00000349285.3  ENSP00000349285     522   \n",
       "5  ENSP00000260777.11  ENSP00000260777     571   \n",
       "6   ENSP00000347532.4  ENSP00000347532     631   \n",
       "7   ENSP00000376635.4  ENSP00000376635     498   \n",
       "8   ENSP00000376636.3  ENSP00000376636     558   \n",
       "9   ENSP00000480109.1  ENSP00000480109     456   \n",
       "\n",
       "                                         proSequence  MISMAP_SCORE_ENSP  \\\n",
       "0  MEGSEPVAAHQGEEASCSSWGTGSTNKNLPIMSTASVEIDDALYSR...               True   \n",
       "1  MEGSEPVAAHQGEEASCSSWGTGSTNKNLPIMSTASVEIDDALYSR...               True   \n",
       "2  MSGARGEGPEAGAGGAGGRAAPENPGGVLSVELPGLLAQLARSFAL...               True   \n",
       "3  MAGIIKKQILKHLSRFTKNLSPDKINLSTLKGEGELKNLELDEEVL...               True   \n",
       "4  MAGIIKKQILKHLSRFTKNLSPDKINLSTLKGEGELKNLELDEEVL...               True   \n",
       "5  MVIEEVNFMQNHLEIEKTCRESAEALATKLNKENKTLKRISMLYMA...               True   \n",
       "6  MNSSDEEKQLQLITSLKEQAIGEYEDLRAENQKTKEKCDKIRQERD...               True   \n",
       "7  MVIEEVNFMQNHLEIEKTCRESAEALATKLNKENKTLKRISMLYMA...               True   \n",
       "8  MNSSDEEKQLQLITSLKEQAIGEYEDLRAENQKTKEKCDKIRQERD...               True   \n",
       "9  MNSSDEEKQLQLITSLKEQAIGEYEDLRAENQKTKEKCDKIRQERD...               True   \n",
       "\n",
       "  UniProtSP_xref  Identical_UKB_seq matchedUKBcanonical  hamming_distance  \\\n",
       "0         A0AVT1               True                True                 0   \n",
       "1         A0AVT1              False               False               684   \n",
       "2         A0FGR8              False               False               859   \n",
       "3         A0JNW5               True                True                 0   \n",
       "4         A0JNW5              False               False               948   \n",
       "5         A0MZ66              False               False               583   \n",
       "6         A0MZ66               True                True                 0   \n",
       "7         A0MZ66              False               False               587   \n",
       "8         A0MZ66              False               False                73   \n",
       "9         A0MZ66              False               False               178   \n",
       "\n",
       "   hamming_normalized_dist  levenshtein_distance  levenshtein_normalized_dist  \n",
       "0                 0.000000                     0                     0.000000  \n",
       "1                 0.650190                   663                     0.630228  \n",
       "2                 0.932682                    77                     0.083605  \n",
       "3                 0.000000                     0                     0.000000  \n",
       "4                 0.647541                   942                     0.643443  \n",
       "5                 0.923930                    60                     0.095087  \n",
       "6                 0.000000                     0                     0.000000  \n",
       "7                 0.930269                   133                     0.210777  \n",
       "8                 0.115689                    73                     0.115689  \n",
       "9                 0.282092                   175                     0.277338  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v97.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>hamming_distance</th>\n",
       "      <th>hamming_normalized_dist</th>\n",
       "      <th>levenshtein_distance</th>\n",
       "      <th>levenshtein_normalized_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10272.000000</td>\n",
       "      <td>10272.000000</td>\n",
       "      <td>10272.000000</td>\n",
       "      <td>10272.000000</td>\n",
       "      <td>10272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>598.666083</td>\n",
       "      <td>229.175623</td>\n",
       "      <td>0.268769</td>\n",
       "      <td>75.427960</td>\n",
       "      <td>0.082515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>931.677181</td>\n",
       "      <td>951.349554</td>\n",
       "      <td>0.375971</td>\n",
       "      <td>541.687178</td>\n",
       "      <td>0.171341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>248.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>429.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>715.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>0.604929</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.078397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>35991.000000</td>\n",
       "      <td>34325.000000</td>\n",
       "      <td>0.999272</td>\n",
       "      <td>34137.000000</td>\n",
       "      <td>0.993799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Length  hamming_distance  hamming_normalized_dist  \\\n",
       "count  10272.000000      10272.000000             10272.000000   \n",
       "mean     598.666083        229.175623                 0.268769   \n",
       "std      931.677181        951.349554                 0.375971   \n",
       "min       35.000000          0.000000                 0.000000   \n",
       "25%      248.000000          0.000000                 0.000000   \n",
       "50%      429.000000          0.000000                 0.000000   \n",
       "75%      715.000000        270.000000                 0.604929   \n",
       "max    35991.000000      34325.000000                 0.999272   \n",
       "\n",
       "       levenshtein_distance  levenshtein_normalized_dist  \n",
       "count          10272.000000                 10272.000000  \n",
       "mean              75.427960                     0.082515  \n",
       "std              541.687178                     0.171341  \n",
       "min                0.000000                     0.000000  \n",
       "25%                0.000000                     0.000000  \n",
       "50%                0.000000                     0.000000  \n",
       "75%               41.000000                     0.078397  \n",
       "max            34137.000000                     0.993799  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describing the column\n",
    "v85.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>hamming_distance</th>\n",
       "      <th>hamming_normalized_dist</th>\n",
       "      <th>levenshtein_distance</th>\n",
       "      <th>levenshtein_normalized_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10479.000000</td>\n",
       "      <td>10479.00000</td>\n",
       "      <td>10479.000000</td>\n",
       "      <td>10479.000000</td>\n",
       "      <td>10479.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>582.769539</td>\n",
       "      <td>215.04781</td>\n",
       "      <td>0.278229</td>\n",
       "      <td>67.820689</td>\n",
       "      <td>0.082460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>877.420592</td>\n",
       "      <td>752.27439</td>\n",
       "      <td>0.380984</td>\n",
       "      <td>402.689523</td>\n",
       "      <td>0.167596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>245.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>425.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>703.000000</td>\n",
       "      <td>274.00000</td>\n",
       "      <td>0.646998</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.085388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34350.000000</td>\n",
       "      <td>32142.00000</td>\n",
       "      <td>0.997551</td>\n",
       "      <td>28825.000000</td>\n",
       "      <td>0.974703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Length  hamming_distance  hamming_normalized_dist  \\\n",
       "count  10479.000000       10479.00000             10479.000000   \n",
       "mean     582.769539         215.04781                 0.278229   \n",
       "std      877.420592         752.27439                 0.380984   \n",
       "min       35.000000           0.00000                 0.000000   \n",
       "25%      245.000000           0.00000                 0.000000   \n",
       "50%      425.000000           0.00000                 0.000000   \n",
       "75%      703.000000         274.00000                 0.646998   \n",
       "max    34350.000000       32142.00000                 0.997551   \n",
       "\n",
       "       levenshtein_distance  levenshtein_normalized_dist  \n",
       "count          10479.000000                 10479.000000  \n",
       "mean              67.820689                     0.082460  \n",
       "std              402.689523                     0.167596  \n",
       "min                0.000000                     0.000000  \n",
       "25%                0.000000                     0.000000  \n",
       "50%                0.000000                     0.000000  \n",
       "75%               41.000000                     0.085388  \n",
       "max            28825.000000                     0.974703  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v92.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>hamming_distance</th>\n",
       "      <th>hamming_normalized_dist</th>\n",
       "      <th>levenshtein_distance</th>\n",
       "      <th>levenshtein_normalized_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10699.000000</td>\n",
       "      <td>10699.000000</td>\n",
       "      <td>10699.000000</td>\n",
       "      <td>10699.00000</td>\n",
       "      <td>10699.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>584.026545</td>\n",
       "      <td>213.942985</td>\n",
       "      <td>0.276695</td>\n",
       "      <td>67.65436</td>\n",
       "      <td>0.082414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>873.117756</td>\n",
       "      <td>746.158567</td>\n",
       "      <td>0.380208</td>\n",
       "      <td>399.61136</td>\n",
       "      <td>0.167505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>245.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>426.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>703.000000</td>\n",
       "      <td>272.500000</td>\n",
       "      <td>0.638012</td>\n",
       "      <td>41.00000</td>\n",
       "      <td>0.085356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34350.000000</td>\n",
       "      <td>32142.000000</td>\n",
       "      <td>0.997551</td>\n",
       "      <td>28825.00000</td>\n",
       "      <td>0.974703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Length  hamming_distance  hamming_normalized_dist  \\\n",
       "count  10699.000000      10699.000000             10699.000000   \n",
       "mean     584.026545        213.942985                 0.276695   \n",
       "std      873.117756        746.158567                 0.380208   \n",
       "min       35.000000          0.000000                 0.000000   \n",
       "25%      245.000000          0.000000                 0.000000   \n",
       "50%      426.000000          0.000000                 0.000000   \n",
       "75%      703.000000        272.500000                 0.638012   \n",
       "max    34350.000000      32142.000000                 0.997551   \n",
       "\n",
       "       levenshtein_distance  levenshtein_normalized_dist  \n",
       "count           10699.00000                 10699.000000  \n",
       "mean               67.65436                     0.082414  \n",
       "std               399.61136                     0.167505  \n",
       "min                 0.00000                     0.000000  \n",
       "25%                 0.00000                     0.000000  \n",
       "50%                 0.00000                     0.000000  \n",
       "75%                41.00000                     0.085356  \n",
       "max             28825.00000                     0.974703  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v94.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>hamming_distance</th>\n",
       "      <th>hamming_normalized_dist</th>\n",
       "      <th>levenshtein_distance</th>\n",
       "      <th>levenshtein_normalized_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10750.000000</td>\n",
       "      <td>10750.000000</td>\n",
       "      <td>10750.000000</td>\n",
       "      <td>10750.000000</td>\n",
       "      <td>10750.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>584.467535</td>\n",
       "      <td>214.605767</td>\n",
       "      <td>0.277247</td>\n",
       "      <td>67.994605</td>\n",
       "      <td>0.082616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>872.508523</td>\n",
       "      <td>745.282945</td>\n",
       "      <td>0.380588</td>\n",
       "      <td>399.397148</td>\n",
       "      <td>0.167981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>245.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>425.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>706.000000</td>\n",
       "      <td>274.000000</td>\n",
       "      <td>0.641072</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.085306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34350.000000</td>\n",
       "      <td>32142.000000</td>\n",
       "      <td>0.997551</td>\n",
       "      <td>28825.000000</td>\n",
       "      <td>0.974703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Length  hamming_distance  hamming_normalized_dist  \\\n",
       "count  10750.000000      10750.000000             10750.000000   \n",
       "mean     584.467535        214.605767                 0.277247   \n",
       "std      872.508523        745.282945                 0.380588   \n",
       "min       35.000000          0.000000                 0.000000   \n",
       "25%      245.000000          0.000000                 0.000000   \n",
       "50%      425.000000          0.000000                 0.000000   \n",
       "75%      706.000000        274.000000                 0.641072   \n",
       "max    34350.000000      32142.000000                 0.997551   \n",
       "\n",
       "       levenshtein_distance  levenshtein_normalized_dist  \n",
       "count          10750.000000                 10750.000000  \n",
       "mean              67.994605                     0.082616  \n",
       "std              399.397148                     0.167981  \n",
       "min                0.000000                     0.000000  \n",
       "25%                0.000000                     0.000000  \n",
       "50%                0.000000                     0.000000  \n",
       "75%               41.000000                     0.085306  \n",
       "max            28825.000000                     0.974703  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v96.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>hamming_distance</th>\n",
       "      <th>hamming_normalized_dist</th>\n",
       "      <th>levenshtein_distance</th>\n",
       "      <th>levenshtein_normalized_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10650.000000</td>\n",
       "      <td>10650.000000</td>\n",
       "      <td>10650.000000</td>\n",
       "      <td>10650.000000</td>\n",
       "      <td>10650.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>582.773052</td>\n",
       "      <td>215.720188</td>\n",
       "      <td>0.278930</td>\n",
       "      <td>68.339061</td>\n",
       "      <td>0.083227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>873.306108</td>\n",
       "      <td>748.005374</td>\n",
       "      <td>0.381136</td>\n",
       "      <td>400.803172</td>\n",
       "      <td>0.168604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>244.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>425.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>705.000000</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>0.646541</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.085901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34350.000000</td>\n",
       "      <td>32142.000000</td>\n",
       "      <td>0.997551</td>\n",
       "      <td>28825.000000</td>\n",
       "      <td>0.974703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Length  hamming_distance  hamming_normalized_dist  \\\n",
       "count  10650.000000      10650.000000             10650.000000   \n",
       "mean     582.773052        215.720188                 0.278930   \n",
       "std      873.306108        748.005374                 0.381136   \n",
       "min       35.000000          0.000000                 0.000000   \n",
       "25%      244.000000          0.000000                 0.000000   \n",
       "50%      425.000000          0.000000                 0.000000   \n",
       "75%      705.000000        276.000000                 0.646541   \n",
       "max    34350.000000      32142.000000                 0.997551   \n",
       "\n",
       "       levenshtein_distance  levenshtein_normalized_dist  \n",
       "count          10650.000000                 10650.000000  \n",
       "mean              68.339061                     0.083227  \n",
       "std              400.803172                     0.168604  \n",
       "min                0.000000                     0.000000  \n",
       "25%                0.000000                     0.000000  \n",
       "50%                0.000000                     0.000000  \n",
       "75%               41.000000                     0.085901  \n",
       "max            28825.000000                     0.974703  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v97.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving ensembl release csv file with identity and distance scores\n",
    "v85.to_csv(\"MISMAP_SCORE_fasta85_CanonicalUKB_identitycol_distanceScores_10272.csv\")  \n",
    "v92.to_csv(\"MISMAP_SCORE_fasta92_CanonicalUKB_identitycol_distanceScores_10479.csv\")  \n",
    "v94.to_csv(\"MISMAP_SCORE_fasta94_CanonicalUKB_identitycol_distanceScores_10699.csv\")  \n",
    "v96.to_csv(\"MISMAP_SCORE_fasta96_CanonicalUKB_identitycol_distanceScores_10750.csv\")  \n",
    "v97.to_csv(\"MISMAP_SCORE_fasta97_CanonicalUKB_identitycol_distanceScores_10650.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALSO did QC for my identity score values\n",
    "- confirm no hidden characters alter identity score (used python strip())- the results were unchanged after QC\n",
    "\n",
    "- confirmed the TRUE and FALSE myidentity score results were correct, all TRUE files  have sequnce identical to my canonical sequences and all FALSE files do not have identical match \n",
    "\n",
    "- MISMAP data code written in 19_09_11_Ensembl_versionIDs_proteinSeq_differences_CYSLYScoordinatesTESTING\n",
    "\n",
    "```python \n",
    "  Identical_UKB_seq  Count\n",
    "0              True   5925\n",
    "1             False   4347\n",
    "\n",
    "  Identical_UKB_seq  Count\n",
    "0              True   5957\n",
    "1             False   4522\n",
    "\n",
    "  Identical_UKB_seq  Count\n",
    "0              True   6097\n",
    "1             False   4602\n",
    "\n",
    "  Identical_UKB_seq  Count\n",
    "0              True   6127\n",
    "1             False   4623\n",
    "\n",
    "  Identical_UKB_seq  Count\n",
    "0              True   6052\n",
    "1             False   4598\n",
    "```\n",
    "\n",
    "## TODO- 2 scripts for QC\n",
    "1. script that confirms results of TRUE FALSE comparing uniprot canonical seq in dict form to the fasta files\n",
    "    - I have each fasta file, seperated into True and False\n",
    "    - double check the True and False files but adding column for specific False reasons the seq does not match\n",
    "    \n",
    "    - added distance metrics \n",
    "        - hamming distance, allows substitutions only\n",
    "        - Levenshtein distance, allows single sub, inser, del only\n",
    "    \n",
    "2. script that confirms results of which Uniprot IDs do not have a canonical sequence match in any of the release fasta files...total 49 canonical sequneces that SHOULD NOT BE PRESENT IN ANY RELEASES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO 2  confirm these 49 IDs do not have a canonical sequence match in any of the Ensembl release fasta files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOUND THESE UNIPROT IDS have canonical sequences that are not in the fasta of ANY RELEASES!!!\n",
    "# DOUBLE CHECK THAT ALL OF THESE SEQUENCES ARE NOT IN THE FASTA FILES\n",
    "\n",
    "noSeqMatchers = ['A0FGR8',\n",
    " 'A6NNF4',\n",
    " 'O14965',\n",
    " 'O15061',\n",
    " 'O15392',\n",
    " 'O43708',\n",
    " 'O60645',\n",
    " 'O75400',\n",
    " 'P02765',\n",
    " 'P07686',\n",
    " 'P11182',\n",
    " 'P11532',\n",
    " 'P11586',\n",
    " 'P16278',\n",
    " 'P17927',\n",
    " 'P18887',\n",
    " 'P20839',\n",
    " 'P30837',\n",
    " 'P36639',\n",
    " 'P53990',\n",
    " 'Q03001',\n",
    " 'Q12912',\n",
    " 'Q13459',\n",
    " 'Q14135',\n",
    " 'Q14558',\n",
    " 'Q15170',\n",
    " 'Q68E01',\n",
    " 'Q6PKG0',\n",
    " 'Q86TG7',\n",
    " 'Q8IY17',\n",
    " 'Q8NBJ7',\n",
    " 'Q8NBT2',\n",
    " 'Q8NCA5',\n",
    " 'Q8WWI1',\n",
    " 'Q8WX93',\n",
    " 'Q96ME1',\n",
    " 'Q99729',\n",
    " 'Q9BV68',\n",
    " 'Q9BX63',\n",
    " 'Q9BZ29',\n",
    " 'Q9NRG7',\n",
    " 'Q9P2N6',\n",
    " 'Q9UJ41',\n",
    " 'Q9UM54',\n",
    " 'Q9UMY4',\n",
    " 'Q9UNH6',\n",
    " 'Q9UNH7',\n",
    " 'Q9Y520',\n",
    " 'Q9Y679']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(noSeqMatchers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "enspA3KN83 = \"MVEPGQDLLLAALSESGISPNDLFDIDGGDAGLATPMPTPSVQQSVPLSALELGLETEAAVPVKQEPETVPTPALLNVRQPPSTTTFVLNQINHLPPLGSTIVMTKTPPVTTNRQTITLTKFIQTTASTRPSVSAPTVRNAMTSAPSKDQVQLKDLLKNNSLNELMKLKPPANIAQPVATAATDVSNGTVKKESSNKEGARMWINDMKMRSFSPTMKVPVVKEDDEPEEEDEEEMGHAETYAEYMPIKLKIGLRHPDAVVETSSLSSVTPPDVWYKTSISEETIDNGWLSALQLEAITYAAQQHETFLPNGDRAGFLIGDGAGVGKGRTIAGIIYENYLLSRKRALWFSVSNDLKYDAERDLRDIGAKNILVHSLNKFKYGKISSKHNGSVKKGVIFATYSSLIGESQSGGKYKTRLKQLLHWCGDDFDGVIVFDECHKAKNLCPVGSSKPTKTGLAVLELQNKLPKARVVYASATGASEPRNMAYMNRLGIWGEGTPFREFSDFIQAVERRGVGAMEIVAMDMKLRGMYIARQLSFTGVTFKIEEVLLSQSYVKMYNKAVKLWVIARERFQQAADLIDAEQRMKKSMWGQFWSAHQRFFKYLCIASKVKRVVQLAREEIKNGKCVVIGLQSTGEARTLEALEEGGGELNDFVSTAKGVLQSLIEKHFPAPDRKKLYSLLGIDLTAPSNNSSPRDSPCKENKIKKRKGEEITREAKKARKVGGLTGSSSDDSGSESDASDNEESDYESSKNMSSGDDDDFNPFLDESNEDDENDPWLIRKDHKKNKEKKKKKSIDPDSIQSALLASGLGSKRPSFSSTPVISPAPNSTPANSNTNSNSSLITSQDAVERAQQMKKDLLDKLEKLAEDLPPNTLDELIDELGGPENVAEMTGRKGRVVSNDDGSISYESRSELDVPVEILNITEKQRFMDGDKNIAIISEAASSGISLQADRRAKNQRRRVHMTLELPWSADRAIQQFGRTHRSNQVTAPEYVFLISELAGEQRFASIVAKRLESLGALTHGDRRATESRDLSRFNFDNKYGRNALEIVMKSIVNLDSPMVSPPPDYPGEFFKDVRQGLIGVGLINVEDRSGILTLDKDYNNIGKFLNRILGMEVHQQNALFQYFADTLTAVVQNAKKNGRYDMGILDLGSGDEKVRKSDVKKFLTPGYSTSGHVELYTISVERGMSWEEATKIWAELTGPDDGFYLSLQIRNNKKTAILVKEVNPKKKLFLVYRPNTGKQLKLEIYADLKKKYKKVVSDDALMHWLDQYNSSADTCTHAYWRGNCKKASLGLVCEIGLRCRTYYVLCGSVLSVWTKVEGVLASVSGTNVKMQIVRLRTEDGQRIVGLIIPANCVSPLVNLLSTSDQSQQLAVQQKQLWQQHHPQSITNLSNA\"\n",
    "\n",
    "ukbA3KN83 = \"MVEPGQDLLLAALSESGISPNDLFDIDGGDAGLATPMPTPSVQQSVPLSALELGLETEAAVPVKQEPETVPTPALLNVRQQPPSTTTFVLNQINHLPPLGSTIVMTKTPPVTTNRQTITLTKFIQTTASTRPSVSAPTVRNAMTSAPSKDQVQLKDLLKNNSLNELMKLKPPANIAQPVATAATDVSNGTVKKESSNKEGARMWINDMKMRSFSPTMKVPVVKEDDEPEEEDEEEMGHAETYAEYMPIKLKIGLRHPDAVVETSSLSSVTPPDVWYKTSISEETIDNGWLSALQLEAITYAAQQHETFLPNGDRAGFLIGDGAGVGKGRTIAGIIYENYLLSRKRALWFSVSNDLKYDAERDLRDIGAKNILVHSLNKFKYGKISSKHNGSVKKGVIFATYSSLIGESQSGGKYKTRLKQLLHWCGDDFDGVIVFDECHKAKNLCPVGSSKPTKTGLAVLELQNKLPKARVVYASATGASEPRNMAYMNRLGIWGEGTPFREFSDFIQAVERRGVGAMEIVAMDMKLRGMYIARQLSFTGVTFKIEEVLLSQSYVKMYNKAVKLWVIARERFQQAADLIDAEQRMKKSMWGQFWSAHQRFFKYLCIASKVKRVVQLAREEIKNGKCVVIGLQSTGEARTLEALEEGGGELNDFVSTAKGVLQSLIEKHFPAPDRKKLYSLLGIDLTAPSNNSSPRDSPCKENKIKKRKGEEITREAKKARKVGGLTGSSSDDSGSESDASDNEESDYESSKNMSSGDDDDFNPFLDESNEDDENDPWLIRKDHKKNKEKKKKKSIDPDSIQSALLASGLGSKRPSFSSTPVISPAPNSTPANSNTNSNSSLITSQDAVERAQQMKKDLLDKLEKLAEDLPPNTLDELIDELGGPENVAEMTGRKGRVVSNDDGSISYESRSELDVPVEILNITEKQRFMDGDKNIAIISEAASSGISLQADRRAKNQRRRVHMTLELPWSADRAIQQFGRTHRSNQVTAPEYVFLISELAGEQRFASIVAKRLESLGALTHGDRRATESRDLSRFNFDNKYGRNALEIVMKSIVNLDSPMVSPPPDYPGEFFKDVRQGLIGVGLINVEDRSGILTLDKDYNNIGKFLNRILGMEVHQQNALFQYFADTLTAVVQNAKKNGRYDMGILDLGSGDEKVRKSDVKKFLTPGYSTSGHVELYTISVERGMSWEEATKIWAELTGPDDGFYLSLQIRNNKKTAILVKEVNPKKKLFLVYRPNTGKQLKLEIYADLKKKYKKVVSDDALMHWLDQYNSSADTCTHAYWRGNCKKASLGLVCEIGLRCRTYYVLCGSVLSVWTKVEGVLASVSGTNVKMQIVRLRTEDGQRIVGLIIPANCVSPLVNLLSTSDQSQQLAVQQKQLWQQHHPQSITNLSNA\"\n",
    "\n",
    "# teh ensp is from v85\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['+ Q']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import difflib\n",
    "output_list = [li for li in difflib.ndiff(enspA3KN83, ukbA3KN83) if li[0] != ' ']\n",
    "output_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
